{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Qountry songs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIcvIw4UN1hS",
        "outputId": "7d20d9d0-5efc-4621-81e1-6dc09b257cbd"
      },
      "source": [
        "!pip install pennylane"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/f9/d3594cf0335d0fb3ec72947bbc6db204f1332588463bb5b9b43083ea35c9/PennyLane-0.14.1.tar.gz (404kB)\n",
            "\r\u001b[K     |▉                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 23.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 11.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 9.8MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.5)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic_version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->pennylane) (4.4.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Building wheels for collected packages: pennylane\n",
            "  Building wheel for pennylane (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pennylane: filename=PennyLane-0.14.1-cp37-none-any.whl size=481980 sha256=8fcd82734d85023e03a18960c42541fa5eb419889ef142f38d6f3b50fd20a9e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/a9/c9/04941d6dd58b3c111cbd1389bf63ba1b23362c137359af4626\n",
            "Successfully built pennylane\n",
            "Installing collected packages: semantic-version, pennylane\n",
            "Successfully installed pennylane-0.14.1 semantic-version-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W-HfYehXz57"
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWrpQ-saDO39",
        "outputId": "e0b9e586-65b1-4064-86ae-d4b5f574ef0f"
      },
      "source": [
        "# Sentiment prediction\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "from pennylane import numpy as np\n",
        "\n",
        "cor_size = 16\n",
        "max_len = 3\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = imdb.load_data(num_words=cor_size)\n",
        "xtrain = preprocessing.sequence.pad_sequences(xtrain, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEKz5nhED-pP"
      },
      "source": [
        "x_train = np.zeros((len(xtrain), 4*max_len))\n",
        "for i, x in enumerate(xtrain):\n",
        "  temp = []\n",
        "  for y in x:\n",
        "    \n",
        "    temp += [int(z) for z in bin(y)[2:].zfill(4)]\n",
        "\n",
        "  x_train[i] = np.array(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPuQ-UiEECIC"
      },
      "source": [
        "import pennylane as qml\n",
        "from pennylane.templates import QAOAEmbedding\n",
        "from pennylane import numpy as np\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=12)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, x=None):\n",
        "  QAOAEmbedding(features=x, weights=weights, wires=range(12))\n",
        "  return qml.expval(qml.PauliZ(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgY3nyXlGMWp"
      },
      "source": [
        "def cost(weights, X=None, y=None):\n",
        "  predictions = [circuit(weights=weights, x=x) for x in X]\n",
        "  \n",
        "  loss = 0\n",
        "  for i in range(len(predictions)):\n",
        "    # v = np.inner(predictions[i], y[i])\n",
        "    # if v==0:\n",
        "    #   v=0.0001\n",
        "    loss += (predictions[i]-y[i])**2\n",
        "  \n",
        "  return loss/(len(predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLLyL_gFG7r6",
        "outputId": "dc3fe808-a44d-4299-9cdd-d79ae7b0322b"
      },
      "source": [
        "X = x_train[:100]\n",
        "y = 2*ytrain[:100]-1\n",
        "weights = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=(4, 24))\n",
        "opt = qml.MomentumOptimizer()\n",
        "n_it = 100\n",
        "loss = []\n",
        "for i in range(n_it):\n",
        "  weights, ls = opt.step_and_cost(lambda w: cost(weights=w, X=X, y=y), weights)\n",
        "  loss.append(ls)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0402421518769924,\n",
              " 1.037450543378709,\n",
              " 1.0323847219237516,\n",
              " 1.025695265303702,\n",
              " 1.0180932423290456,\n",
              " 1.0102807230759767,\n",
              " 1.0028860787477196,\n",
              " 0.9964091809898271,\n",
              " 0.991183194455509,\n",
              " 0.9873584905946968,\n",
              " 0.9849106501355505,\n",
              " 0.9836699027451752,\n",
              " 0.9833653668597264,\n",
              " 0.9836753821122963,\n",
              " 0.9842754553170485,\n",
              " 0.9848773725292748,\n",
              " 0.9852558998756652,\n",
              " 0.9852622700526658,\n",
              " 0.9848257443191026,\n",
              " 0.9839457752109569,\n",
              " 0.982677784637585,\n",
              " 0.9811155427432923,\n",
              " 0.9793727987822937,\n",
              " 0.9775663213418642,\n",
              " 0.9758019313478745,\n",
              " 0.9741645022979611,\n",
              " 0.972712297579732,\n",
              " 0.9714754623426346,\n",
              " 0.9704580396871725,\n",
              " 0.9696425813748069,\n",
              " 0.9689962925006407,\n",
              " 0.968477679154979,\n",
              " 0.9680428239896536,\n",
              " 0.9676506479585203,\n",
              " 0.9672667766647334,\n",
              " 0.966865874751698,\n",
              " 0.9664325138248835,\n",
              " 0.9659607853243395,\n",
              " 0.965452958109957,\n",
              " 0.9649175172650518,\n",
              " 0.9643669153704683,\n",
              " 0.9638153308172319,\n",
              " 0.963276669774493,\n",
              " 0.9627629785016716,\n",
              " 0.962283359130445,\n",
              " 0.9618434121651813,\n",
              " 0.9614451688330683,\n",
              " 0.9610874305267342,\n",
              " 0.9607664034534505,\n",
              " 0.9604765046767163,\n",
              " 0.9602112194861063,\n",
              " 0.9599639063763182,\n",
              " 0.9597284708096288,\n",
              " 0.9594998580240047,\n",
              " 0.9592743443722982,\n",
              " 0.9590496327168122,\n",
              " 0.9588247779381743,\n",
              " 0.958599982402213,\n",
              " 0.9583763080180536,\n",
              " 0.9581553518953402,\n",
              " 0.9579389277445334,\n",
              " 0.9577287865882138,\n",
              " 0.9575263997072377,\n",
              " 0.9573328155941131,\n",
              " 0.9571485923508459,\n",
              " 0.9569737984346244,\n",
              " 0.9568080685226928,\n",
              " 0.9566506977573646,\n",
              " 0.9565007566304864,\n",
              " 0.9563572099028872,\n",
              " 0.9562190256922993,\n",
              " 0.956085264593454,\n",
              " 0.955955142816385,\n",
              " 0.9558280673180632,\n",
              " 0.9557036443496284,\n",
              " 0.9555816654768264,\n",
              " 0.9554620768248554,\n",
              " 0.9553449380465837,\n",
              " 0.9552303774137526,\n",
              " 0.9551185486541194,\n",
              " 0.9550095939144073,\n",
              " 0.9549036157405986,\n",
              " 0.9548006594400291,\n",
              " 0.9547007057969431,\n",
              " 0.954603672981113,\n",
              " 0.9545094256936945,\n",
              " 0.9544177891603686,\n",
              " 0.9543285654909133,\n",
              " 0.9542415501233207,\n",
              " 0.9541565464847178,\n",
              " 0.9540733775454545,\n",
              " 0.9539918935328501,\n",
              " 0.9539119756336517,\n",
              " 0.953833535991896,\n",
              " 0.9537565146642399,\n",
              " 0.9536808744111557,\n",
              " 0.9536065942810459,\n",
              " 0.9535336629022048,\n",
              " 0.9534620722613951,\n",
              " 0.953391812550376]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA4kiTscJCMx",
        "outputId": "8b71297c-de01-46ab-e385-e49d1f53e0bc"
      },
      "source": [
        "predictions = [circuit(weights=weights, x=x) for x in X]\n",
        "predictions = [np.sign(p) for p in predictions]\n",
        "training_accuracy = list(predictions*y).count(1)/len(y)\n",
        "training_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3_KjczHJHcV",
        "outputId": "e68ba57e-fbee-4a41-a549-bae713988c0b"
      },
      "source": [
        "xtest = preprocessing.sequence.pad_sequences(xtest, maxlen=max_len)\n",
        "x_test = np.zeros((len(xtest), 4*max_len))\n",
        "for i, x in enumerate(xtest):\n",
        "  temp = []\n",
        "  for y in x:\n",
        "    # print(bin(y)[2:].zfill(7))\n",
        "    # x_train[i] = []\n",
        "    temp += [int(z) for z in bin(y)[2:].zfill(4)]\n",
        "    # x_train[i] = [int(z) for z in bin(y)[2:].zfill(7)]\n",
        "  x_test[i] = np.array(temp) \n",
        "\n",
        "xt = x_test[:25]\n",
        "yt = 2*ytest[:25]-1\n",
        "predictions = [circuit(weights=weights, x=x) for x in xt]\n",
        "predictions = [np.sign(p) for p in predictions]\n",
        "accuracy = list(predictions*yt).count(1)/len(yt)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_8WnT8V38t",
        "outputId": "12cb39f2-5451-443a-8d92-c8dacdc20e70"
      },
      "source": [
        "# Auto-completer\n",
        "import pennylane as qml\n",
        "from pennylane.templates import QAOAEmbedding\n",
        "from pennylane import numpy as np\n",
        "import string \n",
        "\n",
        "corpus = \"Same old dive, same old end of the work week drink Bartender knows my name, but I don't mind She kicks 'em up strong, serves me up right And here I go again I'm drinkin' one, I'm drinkin' two I got my heartache medication, a strong dedication To gettin' over you, turnin' me loose On that hardwood jukebox lost in neon time My heartache medication, well it suits me fine And I'm drinkin' enough to take you off my mindI got my heartache medication\"\n",
        "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "corpus = corpus.translate(table)\n",
        "tokens = list(corpus.lower().split())\n",
        "w = 2\n",
        "print(len(tokens))\n",
        "vocab, index = {}, 1 # start indexing from 1\n",
        "reverse_vocab = {}\n",
        "vocab['<pad>'] = 0 # add a padding token \n",
        "for token in tokens:\n",
        "  if token not in vocab: \n",
        "    vocab[token] = index\n",
        "    index += 1\n",
        "\n",
        "for item in vocab.keys():\n",
        "  reverse_vocab[vocab[item]] = item\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(vocab)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(w, len(tokens)):\n",
        "  temp1 = []\n",
        "  temp2 = np.array([0]*2**7)\n",
        "  for j in range(1,w+1):\n",
        "    # index.append(bin(vocab[corpus[i-j]])[2:])\n",
        "    temp1 += [int(z) for z in bin(vocab[tokens[i-j]])[2:].zfill(7)]\n",
        "  temp2[vocab[tokens[i]]] = 1\n",
        "  X.append(temp1)\n",
        "  y.append(temp2)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n",
            "{'<pad>': 0, 'same': 1, 'old': 2, 'dive': 3, 'end': 4, 'of': 5, 'the': 6, 'work': 7, 'week': 8, 'drink': 9, 'bartender': 10, 'knows': 11, 'my': 12, 'name': 13, 'but': 14, 'i': 15, 'dont': 16, 'mind': 17, 'she': 18, 'kicks': 19, 'em': 20, 'up': 21, 'strong': 22, 'serves': 23, 'me': 24, 'right': 25, 'and': 26, 'here': 27, 'go': 28, 'again': 29, 'im': 30, 'drinkin': 31, 'one': 32, 'two': 33, 'got': 34, 'heartache': 35, 'medication': 36, 'a': 37, 'dedication': 38, 'to': 39, 'gettin': 40, 'over': 41, 'you': 42, 'turnin': 43, 'loose': 44, 'on': 45, 'that': 46, 'hardwood': 47, 'jukebox': 48, 'lost': 49, 'in': 50, 'neon': 51, 'time': 52, 'well': 53, 'it': 54, 'suits': 55, 'fine': 56, 'enough': 57, 'take': 58, 'off': 59, 'mindi': 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpkrKt3z3qcv"
      },
      "source": [
        "dev = qml.device(\"default.qubit\", wires=14)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, x=None):\n",
        "  QAOAEmbedding(features=x, weights=weights, wires=range(14))\n",
        "  return qml.probs(wires=range(7))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvzvI1bNrNgv"
      },
      "source": [
        "def cost(weights, X=None, y=None):\n",
        "  predictions = [circuit(weights=weights, x=x) for x in X]\n",
        "  \n",
        "  loss = 0\n",
        "  for i in range(len(predictions)):\n",
        "    v = np.inner(predictions[i], y[i])\n",
        "    # if v==0:\n",
        "    #   v=0.0001\n",
        "    loss -= v\n",
        "  \n",
        "  return loss\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTgeYQsirVnc",
        "outputId": "8b16e17b-144a-4496-aff6-1b2009a78784"
      },
      "source": [
        "# weights = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=(4, 28))\n",
        "opt = qml.MomentumOptimizer()\n",
        "n_it = 10\n",
        "loss = []\n",
        "for i in range(n_it):\n",
        "  weights, ls = opt.step_and_cost(lambda w: cost(weights=w, X=X, y=y), weights)\n",
        "  loss.append(ls)\n",
        "loss"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-31.197485094847583,\n",
              " -31.261759697959462,\n",
              " -31.366847806003523,\n",
              " -31.493335549709826,\n",
              " -31.63726835244995,\n",
              " -31.8027456960928,\n",
              " -31.989154248567292,\n",
              " -32.18931506642419,\n",
              " -32.39744951647307,\n",
              " -32.6140496230716]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf8y61zsU05v",
        "outputId": "ee5056ff-d168-4ff8-df82-eebfb28de14b"
      },
      "source": [
        "loss"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-31.197485094847583,\n",
              " -31.261759697959462,\n",
              " -31.366847806003523,\n",
              " -31.493335549709826,\n",
              " -31.63726835244995,\n",
              " -31.8027456960928,\n",
              " -31.989154248567292,\n",
              " -32.18931506642419,\n",
              " -32.39744951647307,\n",
              " -32.6140496230716]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXzAnVCYrscE",
        "outputId": "53d68867-4a4d-4ca1-ea8d-c84c80fb4fe7"
      },
      "source": [
        "def func(x):\n",
        "  index = x[0:7]\n",
        "  first_index = 0\n",
        "  for i, j in enumerate(index):\n",
        "    first_index += 2**(6-i)*j\n",
        "  \n",
        "  index = x[7:]\n",
        "  second_index = 0\n",
        "  for i, j in enumerate(index):\n",
        "    second_index += 2**(6-i)*j\n",
        "  \n",
        "  return first_index, second_index\n",
        "\n",
        "def accuracy(predictions, labels):\n",
        "  return 1/len(predictions)*[p==l for p,l in zip(predictions, labels)].count(True) \n",
        "\n",
        "\n",
        "print(corpus)\n",
        "predicted_words = []\n",
        "labels = []\n",
        "similarity = []\n",
        "for i, context in enumerate(X):\n",
        "  prediction = circuit(weights, x=context)\n",
        "  index = np.argmax(prediction)\n",
        "  # predicted_words.append(reverse_vocab[index])\n",
        "  # print(reverse_vocab())\n",
        "  first_index, second_index = func(context)\n",
        "  # print(\"{}\".format())\n",
        "  # print(reverse_vocab[int(second_index)], reverse_vocab[int(first_index)])\n",
        "  if index not in reverse_vocab.keys():\n",
        "      print(\"no prediction!\")\n",
        "  else:\n",
        "    predicted_words.append(reverse_vocab[index])\n",
        "    labels.append(reverse_vocab[np.argmax(y[i])])\n",
        "    similarity.append(np.inner(prediction, y[i]))\n",
        "    a, b, c, d = reverse_vocab[int(second_index)], reverse_vocab[int(first_index)], reverse_vocab[index],  reverse_vocab[np.argmax(y[i])]\n",
        "    print(\"{}  {}, {} | {}\".format(a, b, c, d))\n",
        "    # print(reverse_vocab[index], reverse_vocab[np.argmax(y[i])])\n",
        "\n",
        "accuracy(predicted_words, labels)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Same old dive same old end of the work week drink Bartender knows my name but I dont mind She kicks em up strong serves me up right And here I go again Im drinkin one Im drinkin two I got my heartache medication a strong dedication To gettin over you turnin me loose On that hardwood jukebox lost in neon time My heartache medication well it suits me fine And Im drinkin enough to take you off my mindI got my heartache medication\n",
            "same  old, dive | dive\n",
            "old  dive, <pad> | same\n",
            "dive  same, old | old\n",
            "same  old, dive | end\n",
            "old  end, of | of\n",
            "end  of, the | the\n",
            "of  the, work | work\n",
            "the  work, end | week\n",
            "work  week, drink | drink\n",
            "week  drink, bartender | bartender\n",
            "drink  bartender, knows | knows\n",
            "bartender  knows, week | my\n",
            "knows  my, name | name\n",
            "my  name, but | but\n",
            "name  but, i | i\n",
            "but  i, my | dont\n",
            "i  dont, mind | mind\n",
            "dont  mind, she | she\n",
            "mind  she, kicks | kicks\n",
            "she  kicks, dont | em\n",
            "kicks  em, up | up\n",
            "em  up, strong | strong\n",
            "up  strong, serves | serves\n",
            "strong  serves, em | me\n",
            "serves  me, right | up\n",
            "me  up, strong | right\n",
            "up  right, and | and\n",
            "right  and, here | here\n",
            "and  here, me | i\n",
            "here  i, my | go\n",
            "i  go, again | again\n",
            "go  again, im | im\n",
            "again  im, drinkin | drinkin\n",
            "im  drinkin, go | one\n",
            "drinkin  one, two | im\n",
            "one  im, drinkin | drinkin\n",
            "im  drinkin, go | two\n",
            "drinkin  two, got | i\n",
            "two  i, my | got\n",
            "i  got, heartache | my\n",
            "got  my, name | heartache\n",
            "my  heartache, one | medication\n",
            "heartache  medication, a | a\n",
            "medication  a, dedication | strong\n",
            "a  strong, serves | dedication\n",
            "strong  dedication, to | to\n",
            "dedication  to, medication | gettin\n",
            "to  gettin, over | over\n",
            "gettin  over, you | you\n",
            "over  you, turnin | turnin\n",
            "you  turnin, gettin | me\n",
            "turnin  me, right | loose\n",
            "me  loose, on | on\n",
            "loose  on, that | that\n",
            "on  that, hardwood | hardwood\n",
            "that  hardwood, loose | jukebox\n",
            "hardwood  jukebox, lost | lost\n",
            "jukebox  lost, in | in\n",
            "lost  in, neon | neon\n",
            "in  neon, jukebox | time\n",
            "neon  time, well | my\n",
            "time  my, name | heartache\n",
            "my  heartache, one | medication\n",
            "heartache  medication, a | well\n",
            "medication  well, it | it\n",
            "well  it, suits | suits\n",
            "it  suits, time | me\n",
            "suits  me, right | fine\n",
            "me  fine, enough | and\n",
            "fine  and, here | im\n",
            "and  im, drinkin | drinkin\n",
            "im  drinkin, go | enough\n",
            "drinkin  enough, take | to\n",
            "enough  to, medication | take\n",
            "to  take, off | you\n",
            "take  you, turnin | off\n",
            "you  off, fine | my\n",
            "off  my, name | mindi\n",
            "no prediction!\n",
            "mindi  got, heartache | my\n",
            "got  my, name | heartache\n",
            "my  heartache, one | medication\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4567901234567901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5oZ9ioWJfHs"
      },
      "source": [
        "# import numpy as np\n",
        "ten_per_cent_vocab = list(vocab.keys())[1:21]\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_pairs(tpv):\n",
        "  pairs = []\n",
        "  for i, word1 in enumerate(tpv):\n",
        "    for word2 in tpv[i+1:]:\n",
        "      pairs.append((word1, word2))\n",
        "      # pairs.append((word2, word1))\n",
        "  return pairs\n",
        "\n",
        "def generate_features(pair):\n",
        "  # for pair in pairs:\n",
        "  temp = []\n",
        "  word1, word2 = pair[0], pair[1]\n",
        "  temp += [int(z) for z in bin(vocab[word2])[2:].zfill(7)]\n",
        "  temp += [int(z) for z in bin(vocab[word1])[2:].zfill(7)]\n",
        "  \n",
        "  return np.array(temp)\n",
        "\n",
        "def generate_lyrics(pairs, window):\n",
        "  lyrics = {}\n",
        "  for i, pair in enumerate(pairs):\n",
        "    if i>8:\n",
        "      break\n",
        "    x = generate_features(pair)\n",
        "    temp = pair[1]\n",
        "    # print(x, temp)\n",
        "    lyrics[i] = [pair[0], pair[1]]\n",
        "    value_window = random.choice(window)\n",
        "    for j in range(value_window):\n",
        "      prediction = circuit(weights, x=x)\n",
        "      index = np.argmax(prediction)\n",
        "      if index not in reverse_vocab.keys():\n",
        "        print(\"no prediction!\")\n",
        "        break\n",
        "      else:\n",
        "        predicted_word = reverse_vocab[index]\n",
        "        # print(predicted_word)\n",
        "        lyrics[i].append(predicted_word)\n",
        "        x = generate_features((temp, predicted_word))\n",
        "        temp = predicted_word\n",
        "  \n",
        "  return lyrics"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEdd_tBMKw-x",
        "outputId": "bc648109-d3ea-488d-b500-c9e44391277b"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "pairs = generate_pairs(ten_per_cent_vocab)\n",
        "shuffle(pairs)\n",
        "lyrics = generate_lyrics(pairs, [2,3])\n",
        "for i in range(8):\n",
        "  verse = \" \".join(lyrics[i]).capitalize()\n",
        "  if i==4:\n",
        "    print(\"\")\n",
        "  print(verse)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Work bartender knows week\n",
            "Same mind she kicks dont\n",
            "Same work end of\n",
            "Dive name but i my\n",
            "\n",
            "The bartender knows week drink\n",
            "My she kicks dont mind\n",
            "Dive but i my name\n",
            "The she kicks dont\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr4GR7wj0mvk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}